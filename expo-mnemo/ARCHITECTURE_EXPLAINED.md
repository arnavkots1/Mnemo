# Architecture Explanation

## How It Works

### ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Mobile App    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Backend Server â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   ML Model      â”‚
â”‚   (Expo Go)     â”‚  HTTP   â”‚   (Node.js)      â”‚  Python â”‚   (TensorFlow)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Records Audio              Receives Request            Classifies Emotion
     Sends to Backend           Loads Model                 Returns Result
     Displays Result            Returns to App
```

### ğŸ“± Mobile App (Expo)

**What it does:**
- Records audio during Capture Session
- Sends audio file to backend
- Receives emotion classification
- Displays results in Moments tab

**What it CAN'T do:**
- âŒ Run Python/TensorFlow models directly
- âŒ Process ML models in Expo Go (limited runtime)

**Why?**
- Expo Go runs JavaScript/TypeScript only
- ML models need Python + TensorFlow (too heavy for mobile)
- Would need native modules (not available in Expo Go)

### ğŸ–¥ï¸ Backend Server (Node.js)

**What it does:**
- âœ… Receives audio files from mobile app
- âœ… Loads ML model on startup (automatic)
- âœ… Calls Python script to classify emotion
- âœ… Returns emotion + confidence to app

**Auto-loads model:**
- When backend starts â†’ checks for `ml_model/saved_model/emotion_model.h5`
- If found â†’ model is ready to use
- If not found â†’ uses stub classifier

### ğŸ¤– ML Model (Python/TensorFlow)

**What it does:**
- Trained CNN model for emotion classification
- Runs on backend server (not in mobile app)
- Processes audio mel spectrograms
- Returns emotion probabilities

**Location:**
- Lives on backend server: `expo-mnemo-backend/ml_model/`
- Trained model saved: `saved_model/emotion_model.h5`
- Loaded automatically when backend starts

---

## ğŸ”„ Flow Example

### 1. User Starts Capture Session
```
Mobile App â†’ Records audio â†’ Saves to device
```

### 2. App Analyzes Audio (Every 10 seconds)
```
Mobile App â†’ Sends audioUri to Backend â†’ Backend receives request
```

### 3. Backend Classifies Emotion
```
Backend â†’ Checks if model loaded â†’ Calls Python script â†’ ML Model processes â†’ Returns emotion
```

### 4. App Receives Result
```
Backend â†’ Returns {emotion: "happy", confidence: 0.85} â†’ Mobile App â†’ Shows alert
```

---

## âœ… Auto-Loading Setup

### Backend Auto-Loads Model

**On Backend Startup:**
```typescript
// server.ts
initializeModel(); // Checks for model, loads if available
```

**What happens:**
- âœ… Checks for `ml_model/saved_model/emotion_model.h5`
- âœ… If found â†’ Model ready for API requests
- âœ… If not found â†’ Uses stub (still works, just not ML)

### App Auto-Configures Backend

**On App Startup:**
```typescript
// App.tsx
initializeApiConfig(); // Configures backend URL
```

**What happens:**
- âœ… Sets backend API URL
- âœ… Enables API usage for emotion & image services
- âœ… App will use backend when available

---

## ğŸš€ How to Use

### Step 1: Train Model (One Time)

```bash
cd expo-mnemo-backend/ml_model
pip install -r requirements.txt
python train_emotion_model.py
```

**Result:** Model saved to `saved_model/emotion_model.h5`

### Step 2: Start Backend

```bash
cd expo-mnemo-backend
npm run dev
```

**What happens:**
- âœ… Backend starts
- âœ… Auto-checks for model
- âœ… If found â†’ "âœ… ML Model found and ready"
- âœ… If not â†’ "âš ï¸ Using stub classifier"

### Step 3: Configure App IP

**Edit `expo-mnemo/config/apiConfig.ts`:**
```typescript
const BACKEND_API_URL = 'http://YOUR_COMPUTER_IP:3000/api';
```

**Find your IP:**
- Windows: `ipconfig` â†’ Look for IPv4 Address
- Mac/Linux: `ifconfig` â†’ Look for inet address

### Step 4: Start App

```bash
cd expo-mnemo
npx expo start
```

**What happens:**
- âœ… App starts
- âœ… Auto-configures backend connection
- âœ… Uses backend for emotion classification

---

## â“ Why Not Run Model in App?

### Technical Limitations

1. **Expo Go Runtime:**
   - Only runs JavaScript/TypeScript
   - Can't run Python code
   - Can't load TensorFlow models directly

2. **Model Size:**
   - TensorFlow models are large (MBs)
   - Would bloat app size
   - Slow to load on mobile

3. **Performance:**
   - ML inference is CPU/GPU intensive
   - Better on server with more resources
   - Mobile battery drain

### Alternative (Future)

**For Production Build:**
- Could use TensorFlow.js (JavaScript ML)
- Would work in production builds
- Still heavier than server-side
- Current approach (backend) is better

---

## ğŸ“ Summary

âœ… **Model loads automatically** when backend starts  
âœ… **App connects automatically** to backend on startup  
âœ… **Everything works together** seamlessly  

**The model runs on the backend, not in the app** - this is the correct architecture! ğŸ¯

